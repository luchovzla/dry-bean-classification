<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>KNN</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"
    integrity="sha384-B0vP5xmATw1+K9KRQjQERJvTumQW0nPEzvF6L/Z6nronJ3oUOFUFpCjEUQouq2+l" crossorigin="anonymous">

  <!-- Our CSS -->
  <link rel="stylesheet" href="style.css">

  <style>
    cite {
      font-style: italic;
    }
  </style>

</head>

<body>

  <div class="container">
    <nav style="background-color:rgb(201, 168, 231) !important"
      class="p-1 navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
      <img src="Images/comp_1_2.gif" alt="Dancing beans" height="42" width="42">
      <a class="navbar-header" href="#"></a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown"
        aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarNavDropdown">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link font-weight-bold" href="index.html" style="color: ghostwhite;">Dry Bean
              Categorization<span class="sr-only">(current)</span></a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link active dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button"
              data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">ML Models</a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
              <a class="dropdown-item" href="random_forest.html">Random Forest</a>
              <a class="dropdown-item" href="mlr.html">Multiple Linear Regression</a>
              <a class="dropdown-item" href="neural_network.html">Neural Network</a>
              <a class="dropdown-item" href="knn.html">K Nearest Neighbors (KNN)</a>
            </div>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="analysis.html" style="color: ghostwhite;">Analysis</a>
          </li>
        </ul>
      </div>
    </nav>

    <div style="background-color:rgb(169, 212, 175) !important" class="jumbotron text-center">
      <div style="text-align: center">
        <h1 style="color: rgb(42, 116, 42)">K-Nearest Neighbor (KNN) Machine Learning Algorithm</h1>
        <img class="center" src="Images/knn3.png" alt="knn" height="400" width="440">

        <br>
        <p>
        </p>
      </div>
    </div>
    <div style="left: auto;">
      <p>K Nearest Neighbors (KNN) is a non-parametric classification method. It is an approach to data classification
        that estimates how likely
        a data point is to be a member of one group or the other depending on what group the data points nearest to it
        are
        in.</p>

      <div style="left: auto;">
        <h2 style="color: rgb(42, 116, 42); text-align: center;">Pros and Cons of KNN</h2>
        <h3 style="color: rgb(42, 116, 42);">Pros</h3>
        <ul class="list">
          <li>
            <p>It is a very simple algorithm to understand.</p>
          </li>
          <li>
            <p>It is very useful for nonlinear data.</p>
          </li>
          <li>
            <p>It is an algorithm we can use for classification as well as regression.</p>
          </li>
          <li>It has relatively high accuracy but there are much better-supervised learning models than KNN.</li>
        </ul>
        <h3 style="color: rgb(42, 116, 42);">Cons</h3>
        <ul class="list">
          <li>
            <p>It uses huge computational resources because it stores all the training data.</p>
          </li>
          <li>
            <p>High memory storage required as compared to other supervised learning algorithms.</p>
          </li>
          <li>
            <p>Prediction is slow when the number of most similar cases, or neighbors is large.</p>
          </li>
          <li>
            <p>It is very sensitive to the scale of data as well as irrelevant features.</p>
          </li>
        </ul>
      </div>
      <div style="left: auto;">
        <h2 style="color: rgb(42, 116, 42); text-align: center;">Applications of KNN</h2>
        <ul class="list">
          <li>
            <p>Banking System: KNN can be used in the banking system to predict whether an individual is fit for loan
              approval.
            </p>
          </li>
          <li>
            <p>Politics: With the help of KNN algorithms, we can classify a potential voter into various classes like
              “Will Vote”, “Will not Vote”, “Will Vote to Party One".</p>
        </ul>
      </div>
    </div>
    <div style="left: auto;">
      <h2 style="color: rgb(42, 116, 42); text-align: center;">Selecting K in KNN</h2>
      <img src="Images/knn_training_accuracy.png" alt="Selecting K" class='img-center'>

    </div>
    <div style="left: auto;">
      <h2 style="color: rgb(42, 116, 42); text-align: center;">Validating K using Cross-Validation for Classification</h2>
      <img src="Images/knn_crossvalidation_accuracy.png" alt="Validating K using Cross-validation" class='img-center'>

    </div>
    <h3 style="color: rgb(42, 116, 42); text-align: center">Analysis</h3>
    <p>A KNN algorithm was used to predict dry beans based on their geometry. After running 10 instances of the algorithm, 
      it was found that the best number of neighbors to use as a parameter was of 15, and the resulting KNN 
      model had an accuracy of 0.922. This was further cross-validated using a Naive Bayes algorithm, which provided the same
      number of neighbors as a result.
    </p>

    <div>
      <br>
      <p><cite>Credits</cite></p>
      <p><cite>KNN Algorithm - Finding Nearest Neighbors</cite>
        https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_knn_algorithm_finding_nearest_neighbors.htm.
      </p>
      <p><cite>k-nearest neighbors algorithm</cite> https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm</p>
      <p><cite>Science Direct k-nearest neighbors</cite>
        https://www.sciencedirect.com/topics/immunology-and-microbiology/k-nearest-neighbor</p>
      <p><cite>Cross-validation using KNN</cite> https://towardsdatascience.com/cross-validation-using-knn-6babb6e619c8
      </p>
    </div>
  </div>

  <!-- Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
    integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
    crossorigin="anonymous"></script>

  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-Piv4xVNRyMGpqkS2by6br4gNJ7DXjqk09RmUpJ8jgGtD7zP9yug3goQfGII0yAns"
    crossorigin="anonymous"></script>

</body>

</html>